{
 "metadata": {
  "name": "",
  "signature": "sha256:9a5d69045048442651e590756706f366d6a2d8e76a3985e4e26acbc6747152b6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Loading data with scikit-learn"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_boston\n",
      "\n",
      "boston = load_boston()\n",
      "print boston['DESCR']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Boston House Prices dataset\n",
        "\n",
        "Notes\n",
        "------\n",
        "Data Set Characteristics:  \n",
        "\n",
        "    :Number of Instances: 506 \n",
        "\n",
        "    :Number of Attributes: 13 numeric/categorical predictive\n",
        "    \n",
        "    :Median Value (attribute 14) is usually the target\n",
        "\n",
        "    :Attribute Information (in order):\n",
        "        - CRIM     per capita crime rate by town\n",
        "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "        - INDUS    proportion of non-retail business acres per town\n",
        "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "        - NOX      nitric oxides concentration (parts per 10 million)\n",
        "        - RM       average number of rooms per dwelling\n",
        "        - AGE      proportion of owner-occupied units built prior to 1940\n",
        "        - DIS      weighted distances to five Boston employment centres\n",
        "        - RAD      index of accessibility to radial highways\n",
        "        - TAX      full-value property-tax rate per $10,000\n",
        "        - PTRATIO  pupil-teacher ratio by town\n",
        "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "        - LSTAT    % lower status of the population\n",
        "        - MEDV     Median value of owner-occupied homes in $1000's\n",
        "\n",
        "    :Missing Attribute Values: None\n",
        "\n",
        "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
        "\n",
        "This is a copy of UCI ML housing dataset.\n",
        "http://archive.ics.uci.edu/ml/datasets/Housing\n",
        "\n",
        "\n",
        "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
        "\n",
        "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
        "prices and the demand for clean air', J. Environ. Economics & Management,\n",
        "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
        "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
        "pages 244-261 of the latter.\n",
        "\n",
        "The Boston house-price data has been used in many machine learning papers that address regression\n",
        "problems.   \n",
        "     \n",
        "**References**\n",
        "\n",
        "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
        "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
        "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import fetch_mldata\n",
      "\n",
      "snowfall = fetch_mldata('whistler daily snowfall')\n",
      "snowfall.data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "(13880, 9)"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import fetch_20newsgroups\n",
      "newsgroups_test = fetch_20newsgroups(subset='test')\n",
      "newsgroups_test.target_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "No handlers could be found for logger \"sklearn.datasets.twenty_newsgroups\"\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "['alt.atheism',\n",
        " 'comp.graphics',\n",
        " 'comp.os.ms-windows.misc',\n",
        " 'comp.sys.ibm.pc.hardware',\n",
        " 'comp.sys.mac.hardware',\n",
        " 'comp.windows.x',\n",
        " 'misc.forsale',\n",
        " 'rec.autos',\n",
        " 'rec.motorcycles',\n",
        " 'rec.sport.baseball',\n",
        " 'rec.sport.hockey',\n",
        " 'sci.crypt',\n",
        " 'sci.electronics',\n",
        " 'sci.med',\n",
        " 'sci.space',\n",
        " 'soc.religion.christian',\n",
        " 'talk.politics.guns',\n",
        " 'talk.politics.mideast',\n",
        " 'talk.politics.misc',\n",
        " 'talk.religion.misc']"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction import DictVectorizer\n",
      "\n",
      "dict_vec = DictVectorizer()\n",
      "restaurants = [{'cuisine': 'Italian', 'distance': 'close', 'rating': 'great'},\n",
      "               {'cuisine': 'French', 'distance': 'far', 'rating': 'good'},\n",
      "               {'cuisine': 'Japanese', 'distance': 'far', 'rating': 'bad'},\n",
      "               {'cuisine': 'Italian', 'distance': 'close', 'rating': 'mediocre'}]\n",
      "\n",
      "dict_vec.fit_transform(restaurants).toarray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "array([[ 0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.],\n",
        "       [ 1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.],\n",
        "       [ 0.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  0.],\n",
        "       [ 0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.]])"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.preprocessing import LabelBinarizer\n",
      "\n",
      "rating = ['bad', 'good', 'great']\n",
      "binarize = LabelBinarizer()\n",
      "binarize.fit_transform(rating)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "array([[1, 0, 0],\n",
        "       [0, 1, 0],\n",
        "       [0, 0, 1]])"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Loading data from outside scikit-learn"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import preprocessing\n",
      "import numpy as np\n",
      "\n",
      "glass_data = np.loadtxt('../data/glass_data.csv', delimiter=',')\n",
      "glass_target = np.loadtxt('../data/glass_target.csv')\n",
      "glass_data[0:5], glass_target[0:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "(array([[  1.52101000e+00,   1.36400000e+01,   4.49000000e+00,\n",
        "           1.10000000e+00,   7.17800000e+01,   6.00000000e-02,\n",
        "           8.75000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
        "        [  1.51761000e+00,   1.38900000e+01,   3.60000000e+00,\n",
        "           1.36000000e+00,   7.27300000e+01,   4.80000000e-01,\n",
        "           7.83000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
        "        [  1.51618000e+00,   1.35300000e+01,   3.55000000e+00,\n",
        "           1.54000000e+00,   7.29900000e+01,   3.90000000e-01,\n",
        "           7.78000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
        "        [  1.51766000e+00,   1.32100000e+01,   3.69000000e+00,\n",
        "           1.29000000e+00,   7.26100000e+01,   5.70000000e-01,\n",
        "           8.22000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
        "        [  1.51742000e+00,   1.32700000e+01,   3.62000000e+00,\n",
        "           1.24000000e+00,   7.30800000e+01,   5.50000000e-01,\n",
        "           8.07000000e+00,   0.00000000e+00,   0.00000000e+00]]),\n",
        " array([ 1.,  1.,  1.,  1.,  1.]))"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "car_data = list(csv.DictReader(open('../data/cardata.csv', 'rU')))\n",
      "car_target = list(csv.reader(open('../data/cartarget.csv', 'rU')))\n",
      "car_data[10], car_target[10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "({'buying': 'vhigh',\n",
        "  'doors': '2',\n",
        "  'lug_boot': 'small',\n",
        "  'maint': 'vhigh',\n",
        "  'persons': '4',\n",
        "  'safety': 'med'},\n",
        " ['unacc'])"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Example for classification\n",
      "import pandas as pd\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "wine_data = pd.read_csv('../data/wine_data.csv')\n",
      "wine_labels = pd.read_csv('../data/wine_labels.csv', squeeze=True)\n",
      "\n",
      "wine_data_train, wine_data_test, wine_labels_train, wine_labels_test = train_test_split(wine_data, wine_labels)\n",
      "wine_data_train[10], wine_labels_train[10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "(array([  1.37400000e+01,   1.67000000e+00,   2.25000000e+00,\n",
        "          1.64000000e+01,   1.18000000e+02,   2.60000000e+00,\n",
        "          2.90000000e+00,   2.10000000e-01,   1.62000000e+00,\n",
        "          5.85000000e+00,   9.20000000e-01,   3.20000000e+00,\n",
        "          1.06000000e+03]), 1)"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Preprocessing strategies"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction import DictVectorizer\n",
      "\n",
      "vec = DictVectorizer()\n",
      "car_data_vec= vec.fit_transform(car_data).toarray()\n",
      "car_data_vec[10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "array([ 0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
        "        0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.])"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}