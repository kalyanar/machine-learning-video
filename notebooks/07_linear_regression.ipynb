{
 "metadata": {
  "name": "",
  "signature": "sha256:0cc3c555893cf9cf9bdf41aa03103d3b3f0428ff2544843725dcb50963f22694"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Introduction to linear regression (5 min)\n",
      "\n",
      "- an approach for exploring the relationship between continuous variables\n",
      "- often will be modeling a dependent variable against explanatory ones\n",
      "- to minimize the residual sum of squares between the observed responses in the dataset, and the responses predicted by the linear approximation\n",
      "    - this means that the model tries to minimize the distance of each datapoint from the predicted line\n",
      "    - Example (go to slide)\n",
      "- When do you want to use linear regression?\n",
      "    - Linear data\n",
      "    - Independent data\n",
      "- Example (go to slide)\n",
      "\n",
      "# Example of linear regression (6 min)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_boston\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "boston = load_boston()\n",
      "lr = LinearRegression()\n",
      "\n",
      "x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target)\n",
      "\n",
      "lr.fit(x_train, y_train)\n",
      "lr.predict(x_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Example of ridge regression (10 min)\n",
      "\n",
      "- works to minimize a penalized version of the least squares cost function using regularization\n",
      "    - regularization is introducing additional information in order to solve an ill-posed problem or to prevent overfitting, and this information is usually of the form of a penalty for complexity\n",
      "    - what this means: goal is to find a model that fits well, so if it were applied to the training set, it should predict the values (or class labels) associated with the samples in that set with a high degree of accuracy \n",
      "    - the cost function quantifies the amount by which the prediction deviates from the actual values\n",
      "- so ridge regression seeks to penalize larger coefficient values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import Ridge\n",
      "\n",
      "lr_ridge = Ridge()\n",
      "lr_ridge.fit(x_train, y_train)\n",
      "lr_ridge.predict(x_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- parameters\n",
      "    - alpha: small positive values of alpha improve the conditioning of the problem and reduce the variance of the estimates. default is 1.\n",
      "    - solver: which solver to use in the computational routines depending on the type of data. default is auto."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr_ridge_param = Ridge(alpha=0.5, solver='lsqr')\n",
      "lr_ridge_param.fit(x_train, y_train)\n",
      "lr_ridge_param.predict(x_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Example of lasso regression (10 min)\n",
      "\n",
      "- linear model that estimates sparse coefficients\n",
      "- useful in some contexts due to its tendency to prefer solutions with fewer parameter values, effectively reducing the number of variables upon which the given solution is dependent\n",
      "- also works to minimize a penalized version of the least squares cost function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import Lasso\n",
      "\n",
      "lr_lasso = Lasso()\n",
      "lr_lasso.fit(x_train, y_train)\n",
      "lr_lasso.predict(x_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- parameters\n",
      "    - alpha again\n",
      "    - normalize: normalize regressors before regression. defaults to false"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr_lasso_param = Lasso(alpha=0.5, normalize=True)\n",
      "lr_lasso_param.fit(x_train, y_train)\n",
      "lr_lasso_param.predict(x_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Comparing models (6 min)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "cross_val_score(lr, boston.data, boston.target)\n",
      "# run cross val on all"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Wrap up (1 min)\n",
      "\n",
      "- What did we learn in this section"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}