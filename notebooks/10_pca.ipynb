{
 "metadata": {
  "name": "",
  "signature": "sha256:7e6fe64cfd340fa6c37ce508574eeb7ac77d9c505daf5700de255258a7d93a1b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Introduction to principal component analysis (7 min)\n",
      "\n",
      "- PCA is used to reduce dimensionality in a multidimensional dataset in a set of successive components that explain a maximum amount of the variance\n",
      "- PCA is implemented as a transformer object that learns n components in its fit method, and can be used on new data to project it on these components\n",
      "- helps w/ curse of dimensionality\n",
      "- The curse of dimensionality - too many dimensions can affect the accuracy of your models. can make your dataset noisy. not all features are needed.\n",
      "- defined in such a way that the first principal component has the largest possible variance (that is, accounts for as much of the variability in the data as possible)\n",
      "- each succeeding component in turn has the highest variance possible under the constraint that it is orthogonal to (i.e., uncorrelated with) the preceding components\n",
      "- use on dataset, and then possibly classify or cluster\n",
      "- When do you want to use PCA?\n",
      "    - high dimensional data\n",
      "\n",
      "# Example of PCA (12 min)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_digits\n",
      "from sklearn.decomposition import PCA\n",
      "\n",
      "digits = load_digits()\n",
      "\n",
      "pca = PCA()\n",
      "# explain output\n",
      "pca.fit(digits.data).transform(digits.data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Tuning parameters (7 min)\n",
      "\n",
      "- n_components: number of components to keep. defaults to all"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# play around with different n_component values\n",
      "target_names = digits.target_names\n",
      "\n",
      "pca_tuned = PCA(n_components=10)\n",
      "pca_tuned.fit(digits.data).transform(digits.data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Evaluation of PCA models (6 min)\n",
      "\n",
      "- explained_variance_ratio attribute: Percentage of variance explained by each of the selected components. sum of explained variances is equal to 1.0"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca.explained_variance_ratio_\n",
      "pca_tuned.explained_variance_ratio_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Wrap up (1 min)\n",
      "\n",
      "- What did we learn in this section?"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}