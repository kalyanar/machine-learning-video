{
 "metadata": {
  "name": "",
  "signature": "sha256:5585a3772920524d674ee5303142a6fed9c5b292a1c602763f451c182de2650e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Part 2"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "from sklearn.feature_extraction import DictVectorizer\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "f = '../data/census_data.csv'\n",
      "\n",
      "census = pd.read_csv(f)\n",
      "\n",
      "new_df = census[(census['native_country'] == 'United-States') &\n",
      "                (census['hours_per_week'] > 10) &\n",
      "                (census['age'] > 20) &\n",
      "                (census['age'] < 50) &\n",
      "                (census['education'] == 'Masters')]\n",
      "new_df_data = new_df.iloc[:, :11]\n",
      "new_df_labels = new_df.iloc[:, -1]\n",
      "\n",
      "new_df_transpose = new_df_data.transpose()\n",
      "\n",
      "data_into_dict = new_df_transpose.to_dict()\n",
      "census_data = [v for k, v in data_into_dict.iteritems()]\n",
      "\n",
      "dv = DictVectorizer()\n",
      "transformed_data = dv.fit_transform(census_data).toarray()\n",
      "\n",
      "le = LabelEncoder()\n",
      "transformed_labels = le.fit_transform(new_df_labels)\n",
      "\n",
      "census_data_train, census_data_test, census_labels_train, census_labels_test = train_test_split(transformed_data, transformed_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Part 3"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.decomposition import PCA\n",
      "\n",
      "# run pca on the dataset\n",
      "\n",
      "# build several random forests models"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Part 4"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "# score them!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}