{
 "metadata": {
  "name": "",
  "signature": "sha256:5808c7410881990afb57905b42d440ba5b1944a09233bd2e718d5f6ffc3a608d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Introduction to random forests (10 min)\n",
      "\n",
      "- What are random forests? \n",
      "    - Ensemble learning method for classification \n",
      "    - operate by constructing multiple decision trees and outputting the most frequent class from those individual trees\n",
      "    - ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms\n",
      "- Explain decision trees\n",
      "    - maps observations about an item to conclusions about the item's target value\n",
      "    - leaves represent class labels and branches represent conjunctions of features that lead to those class labels\n",
      "    - For example... (go to slide)\n",
      "- Back to random forests\n",
      "    - Uses a combination of bagging, or bootstrap aggregating, with random selection of features\n",
      "    - bootstrap aggregating: generating a new sample set from a training set by sampling with replacement, which means that some observations may be repeated in each new sample set\n",
      "    - models are fitted using the bootstrap samples and combined by averaging the classification results\n",
      "    - this, combined with a random selection of the features present in the dataset\n",
      "- When do you want to use random forests?\n",
      "    - Heterogenous data! random forests are great at handling datasets made up of different kinds of data\n",
      "    - Linearly separable data\n",
      "- When do you not?\n",
      "    - Nonlinear data\n",
      "\n",
      "# Example of random forests in scikit-learn (12 min)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_iris\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "iris = load_iris()\n",
      "tree = RandomForestClassifier()\n",
      "\n",
      "iris_train, iris_test, label_train, label_test = train_test_split(iris.data, iris.target)\n",
      "\n",
      "tree.fit(iris_train, label_train)\n",
      "predicted = tree.predict(iris_test)\n",
      "predicted[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "label_test[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Tuning parameters (6 min)\n",
      "\n",
      "- n_estimators: The number of trees in the forest\n",
      "- criterion: The function to measure the quality of a split. Supported criteria are \u201cgini\u201d for the Gini impurity and \u201centropy\u201d for the information gain\n",
      "- max_features: The number of features to consider when looking for the best split\n",
      "- random_state: If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random.\n",
      "\n",
      "Demo each."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tree_tuned = RandomForestClassifier(criterion='entropy')\n",
      "\n",
      "tree_tuned.fit(iris_train, label_train)\n",
      "predicted = tree_tuned.predict(iris_test)\n",
      "predicted[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "label_test[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Evaluating our model (6 min)\n",
      "\n",
      "- use cross_val_score to score each of the different models we came up with."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "cross_val_score(tree, iris.data, iris.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cross_val_score(tree_tuned, iris.data, iris.target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Wrap up (1 min)\n",
      "\n",
      "- In this section, what did we learn?"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}