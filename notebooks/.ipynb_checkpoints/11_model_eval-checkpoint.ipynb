{
 "metadata": {
  "name": "",
  "signature": "sha256:b2685cfff5b5cbd0ac74ecee96da753271c4c68134ccf40c6b381d14995d0396"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Model evaluation methods"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.datasets import load_iris\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "iris = load_iris()\n",
      "tree = DecisionTreeClassifier()\n",
      "\n",
      "iris_train, iris_test, label_train, label_test = train_test_split(iris.data, iris.target)\n",
      "\n",
      "tree.fit(iris_train, label_train)\n",
      "predicted = tree.predict(iris_test)\n",
      "\n",
      "confusion_matrix(label_test, predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "array([[11,  0,  0],\n",
        "       [ 0, 12,  0],\n",
        "       [ 0,  1, 14]])"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import precision_score\n",
      "\n",
      "precision_score(label_test, predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "0.9757085020242916"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import recall_score\n",
      "\n",
      "recall_score(label_test, predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "0.97368421052631582"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import classification_report\n",
      "\n",
      "print classification_report(label_test, predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       1.00      1.00      1.00        11\n",
        "          1       0.92      1.00      0.96        12\n",
        "          2       1.00      0.93      0.97        15\n",
        "\n",
        "avg / total       0.98      0.97      0.97        38\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import explained_variance_score\n",
      "from sklearn.datasets import load_boston\n",
      "from sklearn.linear_model import LinearRegression\n",
      "\n",
      "boston = load_boston()\n",
      "lr = LinearRegression()\n",
      "\n",
      "x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target)\n",
      "\n",
      "lr.fit(x_train, y_train)\n",
      "lr_predicted = lr.predict(x_test)\n",
      "\n",
      "explained_variance_score(y_test, lr_predicted) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "0.72368545280206309"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Grid search?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}